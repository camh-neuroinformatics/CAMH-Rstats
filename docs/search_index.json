[
["index.html", "CAMH R-stats Workshops Chapter 1 Prerequisites 1.1 RStudio environment 1.2 Loading libraries / installing packages", " CAMH R-stats Workshops Erin Dickie 2018-11-15 Chapter 1 Prerequisites Please have these both installed (come early if you need help): R: Download from here rstudio: Download from here Also, please install here awesome R packages (again, if you don’t know how please come early): rms tidyverse This book works from the following files of fake clinical data, that can be downloaded from the following links: messy_demographic.csv messy_cognitive.csv messy_cognitive.csv 1.1 RStudio environment Welcome to R studio! You should see 4 spaces: Source Your script! everything you do to your data should be typed here!! It saves what you are doing in a file ending in ‘.R’ Console The place where the good stuff happens. When you run a command, you see the output here. Enviroment/History Enviroment: a list of everything in your “Workspace” History: a list of every command you have run Files/Plots/Packages/Help Files: a file browser (like windows Explorer) Plots: your plots will show up here Packages: a list of all the packages you have installed with checkboxes showing if it is loaded Help: your help documentation with be shown here. 1.2 Loading libraries / installing packages for this tutorial, we are going to use the packages ggplot, rms and car. Look at the Packages Tab Click on the check box to the left of “ggplot2” Notice that a bunch of lines start running in Console window to show you that the package is loading Go to the History Tab (top right corner) Notice that you should see lines starting in library(“rms”..) and library(“ggplot2”…) have just run Click on these lines to highlight them, then click on To Source at the top of the panel This moves the lines we just ran into our script so we can rerun this step tomorrow! library(tidyverse) "],
["importing-data-into-r.html", "Chapter 2 Importing Data into R 2.1 Read in data 2.2 Basic data summaries and visualization ( head, tail, describe() ) 2.3 Data cleaning 2.4 Merging data frames", " Chapter 2 Importing Data into R 2.1 Read in data The two datasets provided are as follows: messy_demographic.csv: 5 variables: age, diagnosis (dx), ethnicity, sex, and subject identifier (subject_ID) messy_cognitive.csv: 4 variables: +three cognitive scores (cog1, cog2, cog3), and subject identifier (subID) In order to view and manipulate this data in R, we need to import the data into our R workspace (the same as you would open a file in excel to edit it). Rstudio trick: Click on the Environment Tab, then click on Import Dataset –&gt; From text File Navigate the browser window to the location of messy_cognitive.csv and click Open This opens a text reader window: You see the raw text on the top and what R will read in (the data frame) at the bottom In my view, it looks like the R is not going to read in the first line as a header..to change this switch the Heading option on the right to yes Click Import Now, if you look at the Environment tab you should see that data1 has been loaded into R, It has 350 rows (or observations) and 5 variables So that you do not have to type this again tomorrow - go to History, click on the line “data1 &lt;- read.csv(…)” and then click on To Source Repeat this whole process for messy_demographic.csv library(readr) data1 &lt;- read_csv(&quot;~/Downloads/messy_demographic.csv&quot;) data2 &lt;- read_csv(&quot;~/Downloads/messy_cognitive.csv&quot;) What you actually did was use the read.csv function… to find out more about this option you can type “?read.csv” in the Console This is the basic syntax of R functions: some.function(“stuff inside to do the function on”) The help document for the read.csv function is shown in the Help tab Now we have two “data frames” loaded into our workspace. They are called data1 and data2. 2.2 Basic data summaries and visualization ( head, tail, describe() ) Now that we have the data loaded, how do we just look at it? The simplest way is with the “View” function within rstudio. In Enviroment tab. Click on the little spreadsheet to teh far right of the data1.csv row… this shows you your data in what looks like a spreadsheet - but you cannot edit it! To look at the top six rows of your data: head(data1) ## # A tibble: 6 x 5 ## subject_ID age sex ethnicity dx ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 SUB_1 43 0 Cauc 0 ## 2 SUB_2 47 1 Cauc 1 ## 3 SUB_3 69 1 Cauc 1 ## 4 SUB_4 51 0 Cauc 1 ## 5 SUB_5 52 1 Cauc 0 ## 6 SUB_6 71 0 AA 1 To look at the bottom six rows: tail(data2) ## # A tibble: 6 x 4 ## subID cog1 cog2 cog3 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 subject345 10.5491439098318 29.0366805293698 50.0341778674542 ## 2 subject346 13.7560798734217 21.047620123942 11.2510017219872 ## 3 subject347 16.4949897425522 33.323511618334 2.42614834379569 ## 4 subject348 11.1612493587292 30.8723352333704 16.0049438698844 ## 5 subject349 15.3654440645612 29.7598065423247 44.3994545119479 ## 6 subject350 13.993297479479 28.3229119000634 11.2012255384154 Using the function names() tells us what all the variables in our dataframe are called. names(data1) ## [1] &quot;subject_ID&quot; &quot;age&quot; &quot;sex&quot; &quot;ethnicity&quot; &quot;dx&quot; the ls() function does the same thing, except it returns the variables in alphabetical order ls(data1) ## [1] &quot;age&quot; &quot;dx&quot; &quot;ethnicity&quot; &quot;sex&quot; &quot;subject_ID&quot; That was all nice, but we want to find out more about this data we can use “summary” summary(data1) ## subject_ID age sex ## Length:350 Length:350 Min. : 0.00 ## Class :character Class :character 1st Qu.: 0.00 ## Mode :character Mode :character Median : 1.00 ## Mean : 29.44 ## 3rd Qu.: 1.00 ## Max. :9999.00 ## NA&#39;s :3 ## ethnicity dx ## Length:350 Length:350 ## Class :character Class :character ## Mode :character Mode :character ## ## ## ## summary(data2) ## subID cog1 cog2 ## Length:350 Length:350 Length:350 ## Class :character Class :character Class :character ## Mode :character Mode :character Mode :character ## cog3 ## Length:350 ## Class :character ## Mode :character 2.3 Data cleaning Now that you have looked at your data - you might have noticed that there are a couple probems The RA that you have been working with have coded missing values in three different ways (“9999”, “missing”,and “NA”) We first need to set these all to NA - which R recognizes as missing value: The following will take all values in data1 that are equal to “”, “missing”, or “9999”, and code them as missing in a way that R understands: data1[data1==&quot;&quot;] &lt;- NA data1[data1==&quot;missing&quot;] &lt;- NA data1[data1==&quot;9999&quot;] &lt;- NA Because R is “smart”, it categorizes data types automatically when data are loaded. Before working with new data, especailly if it is real (i.e. messy), it is important to tell R what kind of data you are dealing with. This will be especially important when we discuss our statistical analyses… after all, R is statistical software. The following will correctly format our variables for analyses: age is a numeric variable ethicity is a discrete factor sex is a discrete factor diagnosis is a discrete factor data1$age &lt;- as.numeric(as.character(data1$age)) data1$ethnicity &lt;- factor(data1$ethnicity,levels=c(&quot;Cauc&quot;,&quot;AA&quot;,&quot;As&quot;,&quot;In&quot;,&quot;Other&quot;)) data1$sex &lt;- factor(data1$sex, levels=c(0,1), labels=c(&quot;Male&quot;,&quot;Female&quot;)) data1$dx &lt;- factor(data1$dx, levels=c(0,1), labels=c(&quot;Control&quot;,&quot;Case&quot;)) By indicating the levels of our factors, we have erased from R the memory that we once had values of “”, “9999”, and “missing” (which up until now R had no reason to assume were not observations). Let us now apply the same cleanup steps to our second data frame: Remove missing: data2[data2==&quot;&quot;] &lt;- NA data2[data2==&quot;missing&quot;] &lt;- NA data2[data2==&quot;9999&quot;] &lt;- NA Correctly format variables for analyses: data2$cog1 &lt;- as.numeric(as.character(data2$cog1)) data2$cog2 &lt;- as.numeric(as.character(data2$cog2)) data2$cog3 &lt;- as.numeric(as.character(data2$cog3)) 2.4 Merging data frames In order to analyze the effect of sex on diagnosis, or perform any other comparison across our data frames, we should merge them. If you remember only this and nothing else today, it will still have been worth your time. Conceptually, merging two data frames assumes that the rows in one correspond to rows in the other, even if they are not in the same order. In order to match up the correct rows between data frames we need to make sure that one column in each spreadsheet can act as a “key” (i.e. each row has a unique value in this key that is the same in both spreadsheets). In our case, we have one subject identifier column in each of our spreadsheets. 2.4.1 First we need to make sure that the values in these columns are the same We are going to make use a package called stringr, which was built to help us manipulate “strings” (string is a computer science word of sets of characters). Note: There are many ways to deal strings in r, too many ways in fact. stringr was created to make the commands working with strings more consistent so that your code will be easier for another person to read. library(stringr) data2$subject_ID &lt;- str_replace(data2$subID,&quot;subject&quot;,&quot;SUB_&quot;) We can then merge the two datasets by specifying their names (in order x,y) and then specifying which columns are to be used as the key to merging the two data frames (by.x and by.y): library(dplyr) alldata &lt;- inner_join(data1,data2,by=&quot;subject_ID&quot;) Skipping ahead a little - now we can look at histograms of our numeric variables, just to see what we are dealing with: hist(data2$cog1) hist(data2$cog2) hist(data2$cog3) hist(data1$age) Now that our data are loaded, cleaned, and merged, it is time to do some basic statistics! 2.4.2 STUDY QUESTION 1: What is the relationship between sex and diagnosis? For this question, our null hypothesis is that there is no difference in the number of males and females between our case and control diagnosis groups The ftable() function will give us a 2 x 2 contingency table of the frequency of observations in each category. the formula syntax “y ~ x” is common in R! ftable(data=alldata,dx~sex) ## dx Control Case ## sex ## Male 37 90 ## Female 127 86 We now want to save that table as an object called “dxXsex_table”: dxXsex_table &lt;- ftable(data=alldata,dx~sex) Now, in order to test our null hypothesis using a chi-squared test, we simply apply the chisq.test() function to that table: chisq.test(dxXsex_table) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: dxXsex_table ## X-squared = 28.415, df = 1, p-value = 9.791e-08 Similarly, we can use the nonparametric Fisher test to get a more exact test statistic: fisher.test(dxXsex_table) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: dxXsex_table ## p-value = 5.68e-08 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 0.1686647 0.4567064 ## sample estimates: ## odds ratio ## 0.279488 A bit more advanced! This will accoplish the same thing as ftable(), except that here we are indexing our alldata dataframe with the R syntax [,]. the blank value for tells R that we want all rows. The c(“dx”,“sex”) value for means we want to use the columns named “dx” and “sex”. the table() function knows to arrange these as a 2 x 2 contingency table. table(alldata[ ,c(&quot;dx&quot;,&quot;sex&quot;)]) ## sex ## dx Male Female ## Control 37 127 ## Case 90 86 2.4.3 STUDY QUESTION 2: What is the relationship between diagnosis and cog1? for this question, our null hypothesis is that there is no difference in cog1 between our case and control diagnosis groups t.test(cog1 ~ dx, data=alldata) ## ## Welch Two Sample t-test ## ## data: cog1 by dx ## t = -6.347, df = 334.92, p-value = 7.133e-10 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.871388 -1.512676 ## sample estimates: ## mean in group Control mean in group Case ## 9.940047 12.132079 ggplot(alldata, aes(x=dx, y=cog1)) + geom_boxplot() ## Warning: Removed 5 rows containing non-finite values (stat_boxplot). P.S.* Here is an R script with all of the steps we went over today!! Download Intro R script © 2018 GitHub, Inc. Terms Privacy Security Status Help Contact GitHub Pricing API Training Blog About "],
["explore-data-with-r.html", "Chapter 3 Explore Data with R 3.1 Getting Started 3.2 Using tableone to make Table 1 of your paper 3.3 Research Question 1 (two group comparison) 3.4 pretty tables with dplyr 3.5 use forcats to label risk_carriers 3.6 Make a simple scatter plot 3.7 Use plotting to show the age by risk carrier interaction 3.8 BONUS section - gather cognitive scores into one plot", " Chapter 3 Explore Data with R 3.1 Getting Started We will be using these three datasets for the analysis today.. Please download the following files: messy_demographic.csv messy_cognitive.csv messy_genotype.csv In this lesson, we are going to start building figures and table from our data. We are going to do so inside an R - notebook, so we can write ourself a little tutorial/report as what we are finding as we go!! To write a report, we will make use of R-Markdown syntax. A cheatsheet for R Markdown Syntax is here. Add a new chunk by clicking the Insert Chunk button on the toolbar or by pressing Ctrl+Alt+I. We are also going to make heavy use of the “tidyverse” suite of packages. These packages include: ggplot2: for plotting (ggplot cheat sheet) dplyr &amp; tidyr: for manipulating dataframes (data Wrangling cheat sheet) knitr: for adding tables to our reports For more info on programming with the tidyverse I highly recommend the online book R for data science by Garrett Grolemund &amp; Hadley Wickham. 3.1.1 The packages for today library(tidyverse) 3.1.2 reading in the data data1 &lt;- read_csv(&quot;~/Desktop/messy_demographic.csv&quot;) data2 &lt;- read_csv(&quot;~/Desktop/messy_cognitive.csv&quot;) data3 &lt;- read_csv(&quot;~/Desktop/messy_genotype.csv&quot;) 3.1.3 copy and paste the cleaning code These are all the things we learned to do in Intro to R. We are going to put them in one big chunk here. library(stringr) data1[data1==&quot;&quot;] &lt;- NA data1[data1==&quot;missing&quot;] &lt;- NA data1[data1==&quot;9999&quot;] &lt;- NA data1 &lt;- data1 %&gt;% mutate(age = as.numeric(age), ethnicity = factor(ethnicity), sex = factor(sex, levels = c(0,1), labels = c(&quot;Male&quot;, &quot;Female&quot;)), dx = factor(dx, levels = c(0,1), labels = c(&quot;Control&quot;, &quot;Case&quot;))) data2[data2==&quot;&quot;] &lt;- NA data2[data2==&quot;missing&quot;] &lt;- NA data2[data2==&quot;9999&quot;] &lt;- NA data2 &lt;- data2 %&gt;% mutate(cog1 = as.numeric(cog1), cog2 = as.numeric(cog2), cog3 = as.numeric(cog3), subject_ID = str_replace(subID, &quot;subject&quot;, &quot;SUB_&quot;)) %&gt;% select(subject_ID, cog1:cog3) data3[data3==&quot;&quot;] &lt;- NA data3[data3==&quot;missing&quot;] &lt;- NA data3[data3==&quot;9999&quot;] &lt;- NA data3 &lt;- data3 %&gt;% mutate(genotype = factor(genotype, levels=c(0,1,2), labels=c(&quot;AA&quot;,&quot;AG&quot;,&quot;GG&quot;)), subject_ID = str_replace(subID, &quot;subject&quot;, &quot;SUB_&quot;)) %&gt;% select(-subID) alldata &lt;- data1 %&gt;% inner_join(data2, by=&quot;subject_ID&quot;) %&gt;% inner_join(data3, by=&quot;subject_ID&quot;) 3.1.4 Let’s see what we have here We can use the summary function (from base R) to get an idea of what is in our dataset. summary will print some summary statistics for numeric variables are counts for our factors. summary(alldata) ## subject_ID age sex ethnicity dx ## Length:350 Min. :22.00 Male :130 AA : 70 Control:166 ## Class :character 1st Qu.:43.00 Female:216 As : 42 Case :178 ## Mode :character Median :49.00 NA&#39;s : 4 Cauc :196 NA&#39;s : 6 ## Mean :50.38 In : 19 ## 3rd Qu.:58.00 Other: 14 ## Max. :89.00 NA&#39;s : 9 ## NA&#39;s :8 ## cog1 cog2 cog3 genotype ## Min. : 2.868 Min. :20.23 Min. : 0.05796 AA :103 ## 1st Qu.: 8.783 1st Qu.:29.22 1st Qu.: 8.82092 AG :145 ## Median :10.939 Median :31.36 Median : 19.79222 GG : 94 ## Mean :11.087 Mean :31.66 Mean : 25.04099 NA&#39;s: 8 ## 3rd Qu.:12.964 3rd Qu.:34.03 3rd Qu.: 35.55916 ## Max. :22.189 Max. :44.74 Max. :104.21326 ## NA&#39;s :5 NA&#39;s :5 NA&#39;s :9 3.2 Using tableone to make Table 1 of your paper Table one is a cool package that creates the demogaphics table. It takes four useful arguments + data: the data to plot + vars: the variables (from your data) to include in your table + factorVars: a list of which variables (in vars) should be treated as factors + strata: the name of a variable to split the table by. library(tableone) CreateTableOne(alldata, vars = c(&quot;age&quot;, &quot;sex&quot;, &quot;genotype&quot;,&quot;ethnicity&quot;, &quot;cog1&quot;, &quot;cog2&quot;, &quot;cog3&quot;), factorVars = c(&quot;sex&quot;, &quot;genotype&quot;,&quot;ethnicity&quot;), strata = &quot;dx&quot;) ## Stratified by dx ## Control Case p test ## n 166 178 ## age (mean (sd)) 50.42 (11.95) 50.57 (11.06) 0.905 ## sex = Female (%) 127 (77.4) 86 (48.9) &lt;0.001 ## genotype (%) 0.371 ## AA 44 (27.2) 58 (33.1) ## AG 68 (42.0) 73 (41.7) ## GG 50 (30.9) 44 (25.1) ## ethnicity (%) 0.523 ## AA 36 (22.4) 32 (18.4) ## As 17 (10.6) 25 (14.4) ## Cauc 92 (57.1) 100 (57.5) ## In 11 ( 6.8) 8 ( 4.6) ## Other 5 ( 3.1) 9 ( 5.2) ## cog1 (mean (sd)) 9.94 (2.91) 12.13 (3.44) &lt;0.001 ## cog2 (mean (sd)) 31.55 (3.88) 31.78 (3.79) 0.573 ## cog3 (mean (sd)) 25.20 (21.76) 25.25 (20.39) 0.982 3.3 Research Question 1 (two group comparison) 3.3.0.1 Is performance on Cognitive Scale One (cog1) associated with Diagnosis (Dx) To test this statistically, we are going to run an independant samples t-test, using the base t.test function. When we call the t.test function, we are going to use “formula” notation. we’re our dependant variable goes on the left side of a ~ and the predictors go to the right i.e. y ~ x. t.test(cog1 ~ dx, data = alldata) ## ## Welch Two Sample t-test ## ## data: cog1 by dx ## t = -6.347, df = 334.92, p-value = 7.133e-10 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.871388 -1.512676 ## sample estimates: ## mean in group Control mean in group Case ## 9.940047 12.132079 One cool thing to remember about everything you do in R is that they generate useful objects we can save. my_ttest_result &lt;- t.test(cog1 ~ dx, data = alldata) my_ttest_result$p.value ## [1] 7.13299e-10 3.3.1 Plotting our result library(ggplot2) ggplot(data = alldata, aes(x = dx, y = cog1)) + geom_boxplot() #### removing NA rows before plotting We can use tidyr’s drop_na to remove rows with NA’s in the dx column alldata %&gt;% drop_na(dx) %&gt;% ggplot(aes(x = dx, y = cog1, fill = dx)) + geom_boxplot() 3.3.1.1 Introducing the the dotplot geom geom_dotplot has to be one of my favs.. Let’s use it in combination with geom_boxplot. Let’s also use the labs() call to relabel our axes with more descriptive titles. Note: by setting labs(x = NULL) we are removing the word “dx” from the bottom of the plot alldata %&gt;% drop_na(dx) %&gt;% ggplot(aes(x = dx, y = cog1, fill = dx)) + geom_dotplot(binaxis = &quot;y&quot;, stackdir = &quot;center&quot;) + geom_boxplot(alpha = 0.5) + # using &quot;alpha&quot; to make the box-plot semi-transparent labs(x = NULL, #remove dx from the bottom y = &quot;Cognitive Score 1&quot;, #add more desciptive title to y-axis fill = &quot;Diagnosis&quot;) # change dx to Diagnosis in the legend 3.4 pretty tables with dplyr In the section below we use two powerful tools from dplyr: summarise: will calculate summary statistics, we are going to ask for three stats here: n_age: the number of valid (i.e. not NA) values for age mean_age: the mean for age (after removing NA values using the na.rm argument) sd_age: the standard deviation for age after removing the NA values group_by: will split the data by the “grouping” variable(s) you input in this case we are asking for separate summary statistics for each diagnostic group, for each genotype After calculating our summary table we are going to call kable, a function in the knitr package. That make the table appear nicer in our “knitted” report. Note: kable has some kewl optional arguments you can use to format you table further, such as col.names, digits, and align. Check out ?kable for more info.. table_2 &lt;- alldata %&gt;% drop_na(dx) %&gt;% group_by(dx,genotype) %&gt;% summarise(n_age = sum(!is.na(age)), #the total number of observations that are NOT NA mean_age = mean(age, na.rm = T), sd_age = sd(age, na.rm = T)) library(knitr) kable(table_2) dx genotype n_age mean_age sd_age Control AA 43 52.00000 10.574002 Control AG 66 49.92424 11.024882 Control GG 50 49.94000 14.217566 Control NA 4 47.50000 12.476645 Case AA 57 55.08772 10.554756 Case AG 71 48.61972 10.355628 Case GG 43 48.37209 11.176129 Case NA 2 38.00000 9.899495 3.5 use forcats to label risk_carriers When working with a genotype of interest, it’s very common group participants into “carriers” and “non-carriers” of a risk-allele. In this dataset, our risk allele is the “G” genotype. We will create a new “risk_carrier” variable by combining levels of the genotype variable. Working with factors in R can be…annoying. Especially when we want to create new factors out of old factors. For this reason, the tidyverse includes a forcats package. That includes many function (all starting with fct_) for doing stuff to factors. We will use fct_collapse to combine the “GG” and “AG” genotype factors into a new “carrier” level in a new factor. library(forcats) alldata &lt;- alldata %&gt;% mutate(risk_carrier = fct_collapse(genotype, carrier = c(&quot;GG&quot;, &quot;AG&quot;), non_carrier = &quot;AA&quot;)) 3.6 Make a simple scatter plot Let’s use geom_point() and geom_smooth, together to create a scatter plot with a trendline. Note: to make the trendline straight, we use “method = lm” when calling geom_smooth(). alldata %&gt;% ggplot(aes(x = age, y = cog1)) + geom_point() + geom_smooth(method = &quot;lm&quot;) 3.7 Use plotting to show the age by risk carrier interaction When we add a new mapping of color = risk_carrier to the top line of our plot this mapping applies to both the points and the trendline. Note: we are using drop_na to remove the NA as a category so that it does not occur as a third color in our plot. alldata %&gt;% drop_na(risk_carrier) %&gt;% ggplot(aes(x = age, y = cog1, color = risk_carrier)) + geom_point() + geom_smooth(method = &quot;lm&quot;) We can use faceting to add and extra dimension - separate plots for male and female subjects. alldata %&gt;% drop_na(risk_carrier,sex) %&gt;% ggplot(aes(x = age, y = cog1, color = risk_carrier)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~sex) facet_grid will allow us to facet by TWO variables. In this case sex and dx. alldata %&gt;% dplyr::filter(!is.na(risk_carrier), !is.na(sex), !is.na(dx)) %&gt;% ggplot(aes(x = age, y = cog1, color = risk_carrier)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + facet_grid(dx~sex) 3.8 BONUS section - gather cognitive scores into one plot One things we want to do sometimes is to stack data from multiple columns in one column. The reason why this is useful, will hopefully become apparent in the next example. This “stacking” task (also refered to as “melting”) is accomplished using gather from the tidyr package. gather creates two new columns from your data: “key” and “value”. + key: a new column that will hold the old variable names from the gathered data + value: a new column that will hold the data values After the key and value arguments. We can tell gather what colums we want to stack using the same syntax used by dplyr’s select(). In this example, we tell it we want to gather our three cognitive scales using starts_with(). library(tidyr) alldata %&gt;% gather(cog_scale, cognitive_score, starts_with(&quot;cog&quot;)) ## # A tibble: 1,050 x 9 ## subject_ID age sex ethnicity dx genotype risk_carrier cog_scale ## &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; ## 1 SUB_1 43.0 Male Cauc Cont… GG carrier cog1 ## 2 SUB_2 47.0 Female Cauc Case AG carrier cog1 ## 3 SUB_3 69.0 Female Cauc Case AA non_carrier cog1 ## 4 SUB_4 51.0 Male Cauc Case GG carrier cog1 ## 5 SUB_5 52.0 Female Cauc Cont… AA non_carrier cog1 ## 6 SUB_6 71.0 Male AA Case AA non_carrier cog1 ## 7 SUB_7 56.0 Female Cauc Case AA non_carrier cog1 ## 8 SUB_8 35.0 Female &lt;NA&gt; Cont… GG carrier cog1 ## 9 SUB_9 42.0 Female Cauc Cont… AG carrier cog1 ## 10 SUB_10 45.0 Female Other Case &lt;NA&gt; &lt;NA&gt; cog1 ## # ... with 1,040 more rows, and 1 more variable: cognitive_score &lt;dbl&gt; The beauty of gather is that it can be combined with other the rest of the tidyverse using the pipe. Let’s feed out gathered result to ggplot. Note: using scales = &quot;free&quot; when faceting will force ggplot to draw a separate axis for each subplot (by default, scales = &quot;fixed&quot;, meaning that the same axes are drawn for each plot). alldata %&gt;% gather(cog_scale, cognitive_score, starts_with(&quot;cog&quot;)) %&gt;% drop_na(risk_carrier, dx) %&gt;% ggplot(aes(x = age, y = cognitive_score, color = risk_carrier)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~cog_scale, scales = &quot;free&quot;) "],
["stats-linear-models.html", "Chapter 4 Stats (Linear Models) 4.1 Set up (Running Intro to R commands) 4.2 A very fast stats refresher!! 4.3 Looking at Cognition 2 vs Age 4.4 Using broom to save/organize model fit numbers 4.5 Example: printing our formatted t 4.6 plotting distributions 4.7 Transforming variables to “normal” 4.8 Using “power transform” from the car library 4.9 Recodeding our genotype into risk-allele carriers vs non-carriers 4.10 Investigating Interactions 4.11 use p.adjust to correct for multiple comparisons 4.12 BONUS SECTION: using rms to get more details 4.13 ols gets more powerful as the model get’s more complicated 4.14 BONUS SECTION 2 - the “right” way to plot….", " Chapter 4 Stats (Linear Models) Please download the following files: messy_demographic.csv messy_cognitive.csv messy_genotype.csv We need ‘rms’, ‘ggplot2’, and ‘car’ packages If you haven’t already installed these: Load the packages library(tidyverse) library(dplyr) library(tidyr) library(broom) library(readr) 4.0.0.1 p.s. today we are going to use the “pipe” %&gt;% %&gt;% is the pipe The pipe takes the data from the left of if and feeds it to the function on the next line. Below are two ways for writing the same command. select(alldata, cog1:cog3) alldata %&gt;% select(cog1:cog3) 4.1 Set up (Running Intro to R commands) Note: we’re going to use read_csv() from the readr package instead of base R’s read.csv because it is a little more robust. messy_demographic &lt;- read_csv(&quot;~/Downloads/messy_demographic.csv&quot;) # put in the location of the downloaded data file 1 messy_cognitive &lt;- read_csv(&quot;~/Downloads/messy_cognitive.csv&quot;) # put in the location of the downloaded data file 2 data3 &lt;- read_csv(&quot;~/Downloads/messy_genotype.csv&quot;) ## Parsed with column specification: ## cols( ## subject_ID = col_character(), ## age = col_character(), ## sex = col_integer(), ## ethnicity = col_character(), ## dx = col_character() ## ) ## Parsed with column specification: ## cols( ## subID = col_character(), ## cog1 = col_character(), ## cog2 = col_character(), ## cog3 = col_character() ## ) ## Parsed with column specification: ## cols( ## subID = col_character(), ## genotype = col_character() ## ) The data should be merged and ready to go from day 1. If not, here’s the code for it: Copied from here ## I&#39;m using require, it&#39;s actually pretty much the same thing as &quot;library&quot; require(dplyr) require(stringr) require(readr) ## we know that we need we have a same missing value issues in all three dataframes ## to avoid copying and pasting 3 times let&#39;s set them to a function recode_missing &lt;- function(df) { df[df==&quot;&quot;] &lt;- NA df[df==&quot;missing&quot;] &lt;- NA df[df==&quot;9999&quot;] &lt;- NA df[df==9999] &lt;- NA return(df) } ## pipeping messy demographic to the function we made ## then defining the factors inside a call to mutate ## note I use readr::parse_number(), which less error prone version of as.numeric() clean_demographic &lt;- messy_demographic %&gt;% recode_missing() %&gt;% mutate(age = parse_number(age), ethnicity = factor(ethnicity, levels=c(&quot;Cauc&quot;,&quot;AA&quot;,&quot;As&quot;,&quot;In&quot;,&quot;Other&quot;)), sex = factor(sex, levels = c(0,1), labels = c(&quot;Male&quot;,&quot;Female&quot;)), dx = factor(dx, levels=c(0,1), labels=c(&quot;Control&quot;,&quot;Case&quot;))) ## recoding missing values in using out hand made recode_missing function ## then I use dplyr mutate_at to convert all 3 cog vars to a number clean_cognitive &lt;- messy_cognitive %&gt;% recode_missing() %&gt;% mutate_at(vars(cog1:cog3), funs(parse_number(.))) ## recode and set genotype to a factor clean_genotype &lt;- messy_genotype %&gt;% recode_missing() %&gt;% mutate(genotype = factor(genotype, levels=c(0,1,2), labels=c(&quot;AA&quot;,&quot;AG&quot;,&quot;GG&quot;))) ## use stringr to make the subject IDs match ## use dplyr&#39;s inner_join to put all three together ## use select to remove the extra column and put &quot;subID&quot; as the first column alldata &lt;- clean_demographic %&gt;% mutate(subID = str_replace(subject_ID, &quot;SUB_&quot;, &quot;subject&quot;)) %&gt;% inner_join(clean_cognitive, by = &quot;subID&quot;) %&gt;% inner_join(clean_genotype, by = &quot;subID&quot;) %&gt;% select(subID, everything(), -subject_ID) ## remove the intermediate data from your workspace rm(messy_demographic, messy_cognitive, messy_genotype, clean_genotype, clean_cognitive, clean_demographic) 4.2 A very fast stats refresher!! 4.2.1 what stat function do I need?? For today, we are going to focus on what are called “parametric” statistics. We can spend a semester (and many people do) describing the uses of different statistical tests. However today, to pick the “best” statistical test there are two real questions: What type of data is my dependant variable (“y”)? What type of data is my independant/predictor variable (“x”)? Dependant Variable (y) Factor Numeric Independant (x) Factor Chi-Squared chisq.test(ftable(y~x)) t-testt.test(y~x) OR ANOVA anova(lm(y~x)) Numeric Logistic Regression glm(y~x,family=binomial()) Correlationcor.test(y~x) OR Regression lm(y ~ x) Combination (or multiple) Logistic Regression glm(y~x1 + x2,family=binomial()) Multiple Regression lm(y ~ x1 + x2) This table is generally works, UNLESS: Your data is not normally distributed (we will test for that later…). is this is an issue..you will need to enter the land of non-parametric statistics Your data is not “independant”, in other words you have a “repeated-measures design” you might need a paired t.test or repeated measures ANOVA You have more than one dependant variable. Then you need to enter the realm of multivariate statistics.. There are tools for all of this in R. But I will not go into them during this tutorial Most of what we want to do, we can do with the linear model (lm) 4.3 Looking at Cognition 2 vs Age The linear model function in R (lm), like many stats functions in R, uses formula notation, where you describe you dependant and independant variables, separated by a tilda ~. Let’s take an example where we want to predict the scores on cognitive scale 2 using our age variable. In the next chuck we create a linear model fit object. An then call summary on that object. fit_cog2_age &lt;-lm(cog2 ~ age, data = alldata) # creates lm &quot;fit&quot; object summary(fit_cog2_age) # prints a summary report of the fit ## ## Call: ## lm(formula = cog2 ~ age, data = alldata) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.8482 -1.9839 -0.0404 1.5766 8.7988 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 20.85385 0.72780 28.65 &lt;2e-16 *** ## age 0.21359 0.01405 15.20 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.947 on 335 degrees of freedom ## (13 observations deleted due to missingness) ## Multiple R-squared: 0.4083, Adjusted R-squared: 0.4065 ## F-statistic: 231.1 on 1 and 335 DF, p-value: &lt; 2.2e-16 4.4 Using broom to save/organize model fit numbers The best part about running stats in R, in contrast to running your stats in some other “point and click” interface. I that your statistical results (i.e. you test stats, residuals, p values) can all be saved into objects that you can later format into tables, plot, print directly into your report…This is very powerful. Statistical result objects can be tough to work with. The broom package extract numbers from statistical fit results into dataframes that are easier to work with. 4.4.1 augment grabs residuals and predicted values cogbyage_aug &lt;- alldata %&gt;% do(augment(lm(cog2~age,data = .))) head(cogbyage_aug) ## .rownames cog2 age .fitted .se.fit .resid .hat ## 1 1 28.82050 43 30.03823 0.1922539 -1.21773373 0.004255104 ## 2 2 37.46947 47 30.89260 0.1680257 6.57687558 0.003250207 ## 3 3 37.72990 69 35.59159 0.3051575 2.13831656 0.010720322 ## 4 4 31.66686 51 31.74696 0.1606849 -0.08009890 0.002972417 ## 5 5 31.41426 52 31.96055 0.1618742 -0.54629124 0.003016580 ## 6 6 36.05572 71 36.01877 0.3293842 0.03695909 0.012490085 ## .sigma .cooksd .std.resid ## 1 2.950925 3.663098e-04 -0.41405515 ## 2 2.929588 8.145312e-03 2.23514884 ## 3 2.949335 2.882992e-03 0.72944467 ## 4 2.951677 1.104278e-06 -0.02721779 ## 5 2.951528 5.213355e-05 -0.18563513 ## 6 2.951679 1.007059e-06 0.01261916 4.4.2 tidy grabs to middle table (beta’s and t-stats) cogbyage_tidy &lt;- alldata %&gt;% do(tidy(lm(cog2~age,data = .))) cogbyage_tidy ## term estimate std.error statistic p.value ## 1 (Intercept) 20.8538467 0.72779789 28.65335 4.088251e-92 ## 2 age 0.2135904 0.01404897 15.20328 4.592760e-40 4.4.3 glance grabs to full model stats cogbyage_glance &lt;- alldata %&gt;% do(glance(lm(cog2~age,data = .))) cogbyage_glance ## r.squared adj.r.squared sigma statistic p.value df logLik ## 1 0.4082732 0.4065069 2.947271 231.1397 4.59276e-40 2 -841.4358 ## AIC BIC deviance df.residual ## 1 1688.872 1700.332 2909.947 335 4.5 Example: printing our formatted t 4.5.1 now that things are nicely organized we can built tables for our publications, compare across models, and print results to our report my_t_stat &lt;- cogbyage_tidy %&gt;% dplyr::filter(term == &quot;age&quot;) %&gt;% select(statistic) %&gt;% round(.,2) ## round to 2 decimal places print(my_t_stat) ## statistic ## 1 15.2 4.5.2 Printing a result to our report The following line: We observe a significant relationship between age adn cognitive scale 2 (t = 15.2, p = 4.592759910^{-40}) was written in markdown as: We observe a significant relationship between age adn cognitive scale 2 (t = 15.2, p = 4.5927599\\times 10^{-40}) 4.6 plotting distributions 4.6.1 Using ggplot to plot a histogram of cognition score 1 ggplot(alldata, aes(x=cog1)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 5 rows containing non-finite values (stat_bin). 4.6.2 Using a combination of “gather” and ggplot to plot all three scores in one plot alldata %&gt;% gather(cognitive_scale, cognitive_score, cog1:cog3) %&gt;% ggplot(aes(x = cognitive_score)) + geom_histogram() + facet_wrap(~cognitive_scale, scales = &quot;free&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 19 rows containing non-finite values (stat_bin). 4.7 Transforming variables to “normal” From the histogram above.. It looks like cog3 is not normally distributed. This is a problem because it violates “the assumption of normally”, and therefore parametric tests (i.e. the linear model) should not be run in this case. One solution to this problem is to transform this variable into normally distributed variables, and then do the stats on those. Let’s use dplyr’s mutate function to calculate a log (i.e. log10) and square-root transform (sqrt). alldata &lt;- alldata %&gt;% mutate(cog3_log = log(cog3), cog3_sqrt = sqrt(cog3)) Let’s plot histograms of these new values alldata %&gt;% gather(cognitive_scale, cognitive_score, cog3_log, cog3_sqrt) %&gt;% ggplot(aes(x = cognitive_score)) + geom_histogram() + facet_wrap(~cognitive_scale, scales = &quot;free&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 18 rows containing non-finite values (stat_bin). 4.8 Using “power transform” from the car library The people behind the car library decided to use their computer’s to find the perfect transform! The function powerTransform magically finds the perfect transform! library(car) ## Loading required package: carData ## ## Attaching package: &#39;car&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## recode ## The following object is masked from &#39;package:purrr&#39;: ## ## some # calculate the best exponent using powerTransform: pT &lt;- powerTransform(alldata$cog3) # apply the power transform and save the result to a new variable alldata$cog3_powerT &lt;- alldata$cog3^pT$lambda ## note ^ is exponent in r Using powerTransform is a little tricky (it requires two steps). When things get tricky in R, it’s nice to wrap what you want to do inside a function. That way, you can call the function instead of remembering all the steps next time you want to do something! ## run the power transform, return the transformed variable ## where x is a vector of values get_pT &lt;- function(x) { pT &lt;- x^powerTransform(x)$lambda return(pT) } alldata &lt;- alldata %&gt;% mutate(cog3_pT = get_pT(cog3)) ggplot(alldata, aes(x=cog3_pT)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 9 rows containing non-finite values (stat_bin). 4.9 Recodeding our genotype into risk-allele carriers vs non-carriers summary(alldata$genotype) ## AA AG GG NA&#39;s ## 103 145 94 8 library(forcats) alldata &lt;- alldata %&gt;% mutate(risk_carrier = fct_recode(genotype, carrier = &quot;GG&quot;, carrier = &quot;AG&quot;, non_carrier = &quot;AA&quot;)) 4.10 Investigating Interactions 4.10.1 fitting our data with an age by risk-carrier interaction The concept of statistical interaction goes by many names and has many definitions. Simply this is the concept that the effect of one variable changes depending on the value of another variable. Interaction is indicated in R formula syntax with a “:” or *, depending on if you want to automatically include the main effects of your interacting variables or not. As a general rule, always use *. fit2 &lt;- lm(cog1 ~ age*risk_carrier, data = alldata) summary(fit2) ## ## Call: ## lm(formula = cog1 ~ age * risk_carrier, data = alldata) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.9601 -1.9774 -0.0874 1.6888 12.2729 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.18323 1.61921 5.671 3.12e-08 *** ## age 0.06365 0.02967 2.145 0.032678 * ## risk_carriercarrier 4.31736 1.85584 2.326 0.020611 * ## age:risk_carriercarrier -0.12545 0.03468 -3.617 0.000345 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.164 on 326 degrees of freedom ## (20 observations deleted due to missingness) ## Multiple R-squared: 0.1272, Adjusted R-squared: 0.1191 ## F-statistic: 15.83 on 3 and 326 DF, p-value: 1.234e-09 alldata %&gt;% drop_na(risk_carrier) %&gt;% ggplot(aes(x = age, y = cog1, color = risk_carrier)) + geom_point() + geom_smooth(method = &quot;lm&quot;) ## Warning: Removed 12 rows containing non-finite values (stat_smooth). ## Warning: Removed 12 rows containing missing values (geom_point). 4.10.2 Plotting all three cognitve variables at once! alldata %&gt;% gather(cognitive_scale, cognitive_score, cog1, cog2, cog3_pT) %&gt;% drop_na(risk_carrier) %&gt;% ggplot(aes(y = cognitive_score, x = age, color = risk_carrier)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~cognitive_scale, scales = &quot;free&quot;) ## Warning: Removed 40 rows containing non-finite values (stat_smooth). ## Warning: Removed 40 rows containing missing values (geom_point). 4.10.3 Running our linear model on all three cognitive variables at once! lm_results &lt;- alldata %&gt;% gather(cognitive_scale, cognitive_score, cog1, cog2, cog3_pT) %&gt;% drop_na(risk_carrier) %&gt;% group_by(cognitive_scale) %&gt;% do(tidy(lm(cognitive_score ~ age*risk_carrier, data = .))) library(knitr) kable(lm_results %&gt;% select(cognitive_scale, term, statistic, p.value) %&gt;% arrange(p.value)) cognitive_scale term statistic p.value cog2 (Intercept) 14.1811015 0.0000000 cog2 age 7.1325824 0.0000000 cog3_pT (Intercept) 5.9003102 0.0000000 cog1 (Intercept) 5.6714248 0.0000000 cog1 age:risk_carriercarrier -3.6168948 0.0003454 cog1 risk_carriercarrier 2.3263728 0.0206113 cog1 age 2.1451691 0.0326778 cog2 age:risk_carriercarrier 0.7207797 0.4715616 cog2 risk_carriercarrier -0.6541716 0.5134625 cog3_pT risk_carriercarrier 0.5955776 0.5518758 cog3_pT age:risk_carriercarrier -0.4754718 0.6347731 cog3_pT age 0.0187474 0.9850542 4.11 use p.adjust to correct for multiple comparisons age_effects &lt;- lm_results %&gt;% dplyr::filter(term == &quot;age&quot;) age_effects$p.FDR &lt;- p.adjust(age_effects$p.value, method = &quot;fdr&quot;) kable(age_effects) cognitive_scale term estimate std.error statistic p.value p.FDR cog1 age 0.0636475 0.0296701 2.1451691 0.0326778 0.0490167 cog2 age 0.1986365 0.0278492 7.1325824 0.0000000 0.0000000 cog3_pT age 0.0001522 0.0081193 0.0187474 0.9850542 0.9850542 4.12 BONUS SECTION: using rms to get more details When you want more detailed info out of your models. The rms library can be very useful. 4.12.0.1 total_behaviour_score ~ age Calculate a composite variable by combining multiple variables Note: new variables can be made easily (using dplyr’s mutate verb) alldata$totalcog &lt;- (alldata$cog1 + alldata$cog3) / alldata$cog2 Simple linear regression (two ways: base package and rms) library(rms) ## Loading required package: Hmisc ## Loading required package: lattice ## Loading required package: survival ## Loading required package: Formula ## ## Attaching package: &#39;Hmisc&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## src, summarize ## The following objects are masked from &#39;package:base&#39;: ## ## format.pval, units ## Loading required package: SparseM ## Loading required package: methods ## ## Attaching package: &#39;SparseM&#39; ## The following object is masked from &#39;package:base&#39;: ## ## backsolve ## ## Attaching package: &#39;rms&#39; ## The following objects are masked from &#39;package:car&#39;: ## ## Predict, vif lm.base &lt;- lm(data=alldata, totalcog ~ age) lm.rms &lt;- ols(data=alldata, totalcog ~ age) Let’s compare the output’s lm.base ## ## Call: ## lm(formula = totalcog ~ age, data = alldata) ## ## Coefficients: ## (Intercept) age ## 1.78587 -0.01219 summary(lm.base) ## ## Call: ## lm(formula = totalcog ~ age, data = alldata) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.0529 -0.5054 -0.1940 0.4352 2.3720 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.785875 0.172793 10.335 &lt; 2e-16 *** ## age -0.012192 0.003346 -3.644 0.000313 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.6966 on 322 degrees of freedom ## (26 observations deleted due to missingness) ## Multiple R-squared: 0.03961, Adjusted R-squared: 0.03663 ## F-statistic: 13.28 on 1 and 322 DF, p-value: 0.0003125 anova(lm.base) ## Analysis of Variance Table ## ## Response: totalcog ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## age 1 6.445 6.4446 13.28 0.0003125 *** ## Residuals 322 156.259 0.4853 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Note: to make the most out of rms package functionality, we need to store summary stats using the datadist() function. That way, when we call summary() on an ols() object (we just made one called “lm.rms”) it will give us useful info. dd.alldata &lt;- datadist(alldata) options(datadist=&quot;dd.alldata&quot;) lm.rms ## Frequencies of Missing Values Due to Each Variable ## totalcog age ## 18 8 ## ## Linear Regression Model ## ## ols(formula = totalcog ~ age, data = alldata) ## ## ## Model Likelihood Discrimination ## Ratio Test Indexes ## Obs 324 LR chi2 13.09 R2 0.040 ## sigma0.6966 d.f. 1 R2 adj 0.037 ## d.f. 322 Pr(&gt; chi2) 0.0003 g 0.160 ## ## Residuals ## ## Min 1Q Median 3Q Max ## -1.0529 -0.5054 -0.1940 0.4352 2.3720 ## ## ## Coef S.E. t Pr(&gt;|t|) ## Intercept 1.7859 0.1728 10.34 &lt;0.0001 ## age -0.0122 0.0033 -3.64 0.0003 ## summary(lm.rms) ## Effects Response : totalcog ## ## Factor Low High Diff. Effect S.E. Lower 0.95 Upper 0.95 ## age 43 58 15 -0.18288 0.050183 -0.28161 -0.084151 anova(lm.rms) ## Analysis of Variance Response: totalcog ## ## Factor d.f. Partial SS MS F P ## age 1 6.444638 6.4446382 13.28 3e-04 ## REGRESSION 1 6.444638 6.4446382 13.28 3e-04 ## ERROR 322 156.258677 0.4852754 Visualize predicted results using rms plot(Predict(lm.rms)) 4.13 ols gets more powerful as the model get’s more complicated This is were we start to add covariates and do multiple regression lm3 &lt;- ols(data=alldata, cog1 ~ age*risk_carrier + sex ) lm3 ## Frequencies of Missing Values Due to Each Variable ## cog1 age risk_carrier sex ## 5 8 8 4 ## ## Linear Regression Model ## ## ols(formula = cog1 ~ age * risk_carrier + sex, data = alldata) ## ## ## Model Likelihood Discrimination ## Ratio Test Indexes ## Obs 326 LR chi2 49.39 R2 0.141 ## sigma3.1587 d.f. 4 R2 adj 0.130 ## d.f. 321 Pr(&gt; chi2) 0.0000 g 1.432 ## ## Residuals ## ## Min 1Q Median 3Q Max ## -7.61165 -2.06275 -0.03454 1.86219 11.69825 ## ## ## Coef S.E. t Pr(&gt;|t|) ## Intercept 9.7644 1.6478 5.93 &lt;0.0001 ## age 0.0622 0.0299 2.08 0.0386 ## risk_carrier=carrier 4.3775 1.8678 2.34 0.0197 ## sex=Female -0.8926 0.3636 -2.45 0.0146 ## age * risk_carrier=carrier -0.1251 0.0349 -3.59 0.0004 ## anova(lm3) ## Analysis of Variance Response: cog1 ## ## Factor d.f. Partial SS ## age (Factor+Higher Order Factors) 2 165.95975 ## All Interactions 1 128.34287 ## risk_carrier (Factor+Higher Order Factors) 2 432.58671 ## All Interactions 1 128.34287 ## sex 1 60.13082 ## age * risk_carrier (Factor+Higher Order Factors) 1 128.34287 ## REGRESSION 4 523.84580 ## ERROR 321 3202.66179 ## MS F P ## 82.97987 8.32 0.0003 ## 128.34287 12.86 0.0004 ## 216.29335 21.68 &lt;.0001 ## 128.34287 12.86 0.0004 ## 60.13082 6.03 0.0146 ## 128.34287 12.86 0.0004 ## 130.96145 13.13 &lt;.0001 ## 9.97714 summary(lm3) ## Effects Response : cog1 ## ## Factor Low High Diff. Effect S.E. ## age 43 58 15 -0.94428 0.26908 ## risk_carrier - non_carrier:carrier 2 1 NA 1.75290 0.41015 ## sex - Male:Female 2 1 NA 0.89259 0.36358 ## Lower 0.95 Upper 0.95 ## -1.47370 -0.41489 ## 0.94596 2.55980 ## 0.17728 1.60790 ## ## Adjusted to: age=49 risk_carrier=carrier 4.14 BONUS SECTION 2 - the “right” way to plot…. How to visualize a significant effect from our regression…Controlling for the other variables in the model…. To visualize a given effect more informatively, we want to caculate the residuals of the model lacking our co-varitate of interest and plot those residuals as our outcome: For genotype we want a boxplot of model residuals: lm3.plot &lt;- ols(data=alldata, cog1 ~ genotype + age) ggplot(data=alldata, aes(y=resid(lm3.plot), x=sex)) + geom_boxplot() ## Warning: Removed 20 rows containing non-finite values (stat_boxplot). "]
]
